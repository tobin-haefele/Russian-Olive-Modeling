---
title: "Russian_Olive_Modeling"
author: "Tobin Haefele"
date: "2025-01-28"
output: html_document
---

```{r setup, include=FALSE}
library(sf)
library(ggplot2)
library(tidyverse)
library(blockCV)
library(randomForest)
library(pdp)

knitr::opts_chunk$set(echo = TRUE)
```

## Import data

```{r data import, warning=FALSE}
# import observations for missoula county field survey
russian_olive_df <- read_csv("data/CombinedDataset.csv", show_col_types = FALSE)

# import missoula county shapefile
msl_shape <- read_sf("data/MontanaStateBoundary_shp/MontanaCounties_shp")
```

## Cleaning data

```{r data cleaning, echo=FALSE}
# Select the Missoula shapefile
msl_shape <- msl_shape %>% filter(NAME == "MISSOULA")

# drop CID column
russian_olive_df <- subset(russian_olive_df,
  select = -c(CID, EVT_NAME_M, SNAME, GNAME, RED, GREEN, BLUE)
)

# remove spaces from column names
colnames(russian_olive_df) <- gsub(" ", "_", colnames(russian_olive_df))

# Convert Missoula shapefile to crs 4326 for conversion to sf object
msl_shape <- st_transform(msl_shape, crs = 4326)

# Convert to sf object for analysis
survey_sf <- st_as_sf(russian_olive_df,
  coords = c("Longitude", "Latitude"),
  crs = 4326
)

# convert PA to factor for random forest model
survey_sf$PA <- as.factor(survey_sf$PA)

# convert all character columns to factors for proper modeling
survey_sf <- survey_sf %>%
  mutate_if(is.character, as.factor)
```

## Testing cleaned data

```{r plot, echo=FALSE}
# plot imported points to test
ggplot() +
  geom_sf(data = msl_shape) +
  geom_sf(data = survey_sf, aes(color = PA))
```

## Prepping the data for modeling

```{r model prep, echo=FALSE}
#set seed for reproducibility
set.seed(1234)

# split data into training/testing accounting for spatial autocorrelation
sb <- cv_spatial(
  x = survey_sf,
  column = "PA",
  k = 10,
  selection = "random",
)

# store the folds for later use
folds <- sb$folds_list
```

## Basic modeling

```{r model, echo=FALSE, warning=FALSE}
# Train and validate a model using the folds
test_table <- survey_sf
test_table$Pred <- as.numeric("NA")

for (k in seq_len(length(folds))) {
  # Extracting the training and testing indices
  train_set <- unlist(folds[[k]][1]) # training set indices; first element
  test_set <- unlist(folds[[k]][2]) # testing set indices; second element

  # Train a random forest model
  rf <- randomForest(PA ~ ., st_drop_geometry(survey_sf[train_set, ]),
    ntree = 500,
    importance = TRUE
  )

  # Predict the test set and store probabilities
  test_table$Pred[test_set] <- predict(rf,
    st_drop_geometry(survey_sf[test_set, ]),
    type = "prob"
  )[, 2]
}
```

```{r results}
# view the variable importance scores
importance_scores <- importance(rf)
print(importance_scores)
varImpPlot(rf)

#view the confusion matrix
rf$confusion

# plot the results
ggplot(test_table) +
  geom_sf(aes(color = Pred), size = 2) + # Color by predicted value
  scale_color_gradient(low = "blue", high = "red") + # Gradient for probability
  labs(
    title = "Predicted Probability of Presence",
    color = "Probability"
  ) +
  theme_minimal()

# pdp plot of each factors importance
pd <- pdp::partial(rf, pred.var = "NEAR_DIST", plot = FALSE)

plotPartial(pd)
```

```{r data output}
#convert sf back to a df, keeping coordinates for plotting
predictions_df <- as.data.frame(test_table) %>%
  mutate(lon = sf::st_coordinates(geometry)[,1],
         lat = sf::st_coordinates(geometry)[,2])
  

```

### Potential Variables to include

-   [x] Wetland Riparian (land cover )
-   [x] Maximum Summer Temp (climate)
-   [x] Frost Free Days (climate)
-   [x] Anthropogenic Influence (land cover)
-   [x] Introduced Vegetation (land cover)
-   [ ] Soil pH (soil)
-   [x] Forest - Conifer (land cover)
-   [ ] Bulk Density (soil)
-   [x] Degree Days (climate)
-   [ ] Distance to Water Edge (hydrography)?

### To Do

-   [ ]  Visualization of current spread (potentially past?), also ornamental vs received (grown naturally)
-   [ ]  add above variables to model
-   [ ]  clean MT state data to under 800 spatial precision
-   [ ]  some kind of polygonal/area analysis
-   [x]  Create outline for paper
-   [ ]  Write paper
-   [ ]  Try different modeling methods
-   [ ] Lay out story map

### Data sets

<https://geoinfo.msl.mt.gov/msdi/land_use_land_cover> <https://geoinfo.msl.mt.gov/msdi/climate/> <https://prism.oregonstate.edu/> <https://doi.org/10.18113/S1KW2H> (soil)
